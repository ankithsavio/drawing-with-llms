{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "393fda5a",
   "metadata": {},
   "source": [
    "## Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a1cfb00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/ankit/Desktop/Portfolio/kaggle/drawing-with-llms\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "781b4f56",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ankith/anaconda3/envs/auto/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import time\n",
    "from typing import List\n",
    "\n",
    "import pandas as pd\n",
    "from camel.agents import ChatAgent\n",
    "from camel.models.model_factory import ModelFactory, ModelPlatformType, ModelType\n",
    "from datasets import load_dataset\n",
    "from dotenv import load_dotenv\n",
    "from pydantic import BaseModel\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "load_dotenv(\".env\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a27085c7",
   "metadata": {},
   "source": [
    "## View Descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dbf22be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ModelFactory.create(\n",
    "    model_platform=ModelPlatformType.OPENAI_COMPATIBLE_MODEL,\n",
    "    model_type=ModelType.GEMINI_2_5_FLASH_PREVIEW,\n",
    "    url=\"https://generativelanguage.googleapis.com/v1beta/openai/\",\n",
    "    api_key=os.getenv(\"GEMINI_API_KEY\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "747a4308",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a purple forest at dusk', 'gray wool coat with a faux fur collar', 'a lighthouse overlooking the ocean', 'burgundy corduroy pants with patch pockets and silver buttons', 'orange corduroy overalls', 'a purple silk scarf with tassel trim', 'a green lagoon under a cloudy sky', 'crimson rectangles forming a chaotic grid', 'purple pyramids spiraling around a bronze cone', 'magenta trapezoids layered on a transluscent silver sheet', 'a snowy plain', 'black and white checkered pants', 'a starlit night over snow-covered peaks', 'khaki triangles and azure crescents', 'a maroon dodecahedron interwoven with teal threads']\n"
     ]
    }
   ],
   "source": [
    "data = load_dataset(\"csv\", data_files=\"data/combined_train.csv\")[\"train\"]\n",
    "\n",
    "print(data[\"description\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8575eceb",
   "metadata": {},
   "source": [
    "We need more descriptions in order to consider Fine Tuning\n",
    "\n",
    "Define a loop to randomly sample descriptions from the dataset and generate more similar samples using Gemini 2.5 Flash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bbedc817",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:05<00:00,  5.17s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cyan triangles arranged on a black velvet surface</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a blue desert under an orange sky</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a red silk scarf with silver sequined fringe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a brown river under a dark blue starry sky</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a faceted golden matte sphere</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         description\n",
       "0  cyan triangles arranged on a black velvet surface\n",
       "1                  a blue desert under an orange sky\n",
       "2       a red silk scarf with silver sequined fringe\n",
       "3         a brown river under a dark blue starry sky\n",
       "4                      a faceted golden matte sphere"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# modified prompt from https://github.com/camel-ai/camel/blob/a48b948cbddd80b1cf5ad4d7ef99b3bfc21ec9ec/camel/datasets/few_shot_generator.py#L32\n",
    "\n",
    "\n",
    "class SampleResponse(BaseModel):\n",
    "    description: str\n",
    "    rationale: str\n",
    "\n",
    "\n",
    "class SampleList(BaseModel):\n",
    "    items: List[SampleResponse]\n",
    "\n",
    "\n",
    "def create_synthetic_dataset(num=100, num_gen=5):\n",
    "    SYSTEM_PROMPT = \"\"\"**You are an advanced data generation assistant.**  \n",
    "    Your goal is to generate high-quality synthetic data samples based on \n",
    "    provided examples. Your output must be well-structured, \n",
    "    logically sound, and formatted correctly. \n",
    "\n",
    "    **Instructions:**\n",
    "    1. **Follow the Structure**  \n",
    "    Each data sample must include:  \n",
    "    - **Description**: A clear, well-formed description of an SVG image.  \n",
    "    - **Rationale**: A step-by-step, reasoning process for generation of the Description.  \n",
    "\n",
    "    2. **Output Format (Strict)**\n",
    "    - A list of json consisteing of five data samples\n",
    "    ```\n",
    "    [{\"description\" : \"Generated description\"\n",
    "    \"rationale\": \"reasoning why this description makes sense as a data sample\"},\n",
    "    ...\n",
    "    ]\n",
    "    ```\n",
    "\n",
    "    **Now, generate 5 new data samples based on the given examples.**\n",
    "    \"\"\"\n",
    "\n",
    "    total_samples = num\n",
    "    num_samples_gen = num_gen\n",
    "    sample_collection = []\n",
    "\n",
    "    agent = ChatAgent(SYSTEM_PROMPT, model=model)\n",
    "\n",
    "    for i in tqdm(range(int(total_samples / num_samples_gen))):\n",
    "        num_examples = random.randrange(5, 10)\n",
    "        indices = [random.randrange(0, len(data)) for _ in range(num_examples)]\n",
    "\n",
    "        # every iteration randomly add samples from the dataset in context\n",
    "        USER_PROMPT = (\n",
    "            \"<examples>\" + \"\\n\".join(data[indices][\"description\"]) + \"</examples>\"\n",
    "        )\n",
    "\n",
    "        sample_list = agent.step(USER_PROMPT, response_format=SampleList).msgs[0].parsed\n",
    "\n",
    "        for sample in sample_list.items:\n",
    "            sample_collection.append(sample.description)\n",
    "\n",
    "        # reset user prompt\n",
    "        agent.reset()\n",
    "        # manual delay for rate limit\n",
    "        time.sleep(2)\n",
    "\n",
    "    if sample_collection:\n",
    "        unique_samples = set(sample_collection)\n",
    "        df = pd.DataFrame({\"description\": list(unique_samples)})\n",
    "        df.dropna(inplace=True)\n",
    "        return df\n",
    "\n",
    "\n",
    "df_save = create_synthetic_dataset(5, 5)\n",
    "# df_save.to_csv(\"data/descriptions.csv\", index=False)\n",
    "df_save.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d32863",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "auto",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
